{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "positive-prevention",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "noted-rotation",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.engine.base_layer' has no attribute 'BaseRandomLayer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_28508/740067183.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#from keras.layers import Input, Dense, SimpleRNN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSGD\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\datascience\\lib\\site-packages\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;31m# See b/110718070#comment18 for more details about this import.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\datascience\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmetrics_module\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0moptimizer_v1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfunctional\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\datascience\\lib\\site-packages\\keras\\metrics.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbase_layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\datascience\\lib\\site-packages\\keras\\activations.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0madvanced_activations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeneric_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdeserialize_keras_object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeneric_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mserialize_keras_object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\datascience\\lib\\site-packages\\keras\\layers\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;31m# Image preprocessing layers.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_preprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCenterCrop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_preprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomCrop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_preprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomFlip\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\datascience\\lib\\site-packages\\keras\\layers\\preprocessing\\image_preprocessing.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbase_layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbase_preprocessing_layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mimage_preprocessing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcontrol_flow_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstateless_random_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\datascience\\lib\\site-packages\\keras\\preprocessing\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtimeseries\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mall_utils\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;31m# This exists for compatibility with prior version of keras_preprocessing.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\datascience\\lib\\site-packages\\keras\\utils\\all_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeneric_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mserialize_keras_object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_source_inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmulti_gpu_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmulti_gpu_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnp_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnp_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\datascience\\lib\\site-packages\\keras\\utils\\multi_gpu_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLambda\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\datascience\\lib\\site-packages\\keras\\layers\\core\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivity_regularization\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mActivityRegularization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDropout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlambda_layer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLambda\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\datascience\\lib\\site-packages\\keras\\layers\\core\\dropout.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0mkeras_export\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'keras.layers.Dropout'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mDropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_layer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBaseRandomLayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m   \"\"\"Applies Dropout to the input.\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'keras.engine.base_layer' has no attribute 'BaseRandomLayer'"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, SimpleRNN\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import to_categorical\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "alternative-monthly",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. LECTURA DEL SET DE DATOS\n",
    "# ===========================================================\n",
    "nombres = open('../DataSets/nombres_dinosaurios.txt','r').read()\n",
    "nombres = nombres.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "racial-batch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En total hay 19909 caracteres, y el diccionario tiene un tamaño de 27 caracteres.\n"
     ]
    }
   ],
   "source": [
    "# Crear diccionario (listado de caracteres que no se repiten)\n",
    "alfabeto = list(set(nombres))\n",
    "tam_datos, tam_alfabeto = len(nombres), len(alfabeto)\n",
    "print(\"En total hay %d caracteres, y el diccionario tiene un tamaño de %d caracteres.\" % (tam_datos, tam_alfabeto))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "scenic-nepal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\n': 0, 'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26}\n",
      "{0: '\\n', 1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z'}\n"
     ]
    }
   ],
   "source": [
    "# Conversión de caracteres a índices y viceversa\n",
    "car_a_ind = { car:ind for ind,car in enumerate(sorted(alfabeto))}\n",
    "ind_a_car = { ind:car for ind,car in enumerate(sorted(alfabeto))}\n",
    "print(car_a_ind)\n",
    "print(ind_a_car)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "swedish-october",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, None, 27)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 25)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)        [(None, 25), (None,  1325        input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 27)           702         simple_rnn_1[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 2,027\n",
      "Trainable params: 2,027\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 2. MODELO\n",
    "# ===========================================================\n",
    "n_a = 25    # Número de unidades en la capa oculta\n",
    "entrada  = Input(shape=(None,tam_alfabeto))\n",
    "a0 = Input(shape=(n_a,))\n",
    "\n",
    "celda_recurrente = SimpleRNN(n_a, activation='tanh', return_state = True)\n",
    "capa_salida = Dense(tam_alfabeto, activation='softmax')\n",
    "\n",
    "salida = []\n",
    "hs, _ = celda_recurrente(entrada, initial_state=a0)\n",
    "salida.append(capa_salida(hs))\n",
    "modelo = Model([entrada,a0],salida)\n",
    "modelo.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "built-penalty",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = SGD(lr=0.0005)\n",
    "modelo.compile(optimizer=opt, loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "sweet-placement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. EJEMPLOS DE ENTRENAMIENTO\n",
    "# ===========================================================\n",
    "\n",
    "# Crear lista con ejemplos de entrenamiento y mezclarla aleatoriamente\n",
    "with open(\"../DataSets/nombres_dinosaurios.txt\") as f:\n",
    "    ejemplos = f.readlines()\n",
    "ejemplos = [x.lower().strip() for x in ejemplos]\n",
    "np.random.shuffle(ejemplos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "disturbed-federal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear ejemplos de entrenamiento usando un generador\n",
    "def train_generator():\n",
    "    while True:\n",
    "        # Tomar un ejemplo aleatorio\n",
    "        ejemplo = ejemplos[np.random.randint(0,len(ejemplos))]\n",
    "\n",
    "        # Convertir el ejemplo a representación numérica\n",
    "        X = [None] + [car_a_ind[c] for c in ejemplo]\n",
    "\n",
    "        # Crear \"Y\", resultado de desplazar \"X\" un caracter a la derecha\n",
    "        Y = X[1:] + [car_a_ind['\\n']]\n",
    "\n",
    "        # Representar \"X\" y \"Y\" en formato one-hot\n",
    "        x = np.zeros((len(X),1,tam_alfabeto))\n",
    "        onehot = to_categorical(X[1:],tam_alfabeto).reshape(len(X)-1,1,tam_alfabeto)\n",
    "        x[1:,:,:] = onehot\n",
    "        y = to_categorical(Y,tam_alfabeto).reshape(len(X),tam_alfabeto)\n",
    "\n",
    "        # Activación inicial (matriz de ceros)\n",
    "        a = np.zeros((len(X), n_a))\n",
    "\n",
    "        yield [x, a], y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "entitled-speaking",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteración: 0, Error: 3.320831\n",
      "\n",
      "\n",
      "Iteración: 100, Error: 3.001484\n",
      "\n",
      "\n",
      "Iteración: 200, Error: 2.837848\n",
      "\n",
      "\n",
      "Iteración: 300, Error: 2.791006\n",
      "\n",
      "\n",
      "Iteración: 400, Error: 2.680443\n",
      "\n",
      "\n",
      "Iteración: 500, Error: 2.619028\n",
      "\n",
      "\n",
      "Iteración: 600, Error: 2.568014\n",
      "\n",
      "\n",
      "Iteración: 700, Error: 2.419670\n",
      "\n",
      "\n",
      "Iteración: 800, Error: 2.498275\n",
      "\n",
      "\n",
      "Iteración: 900, Error: 2.406559\n",
      "\n",
      "\n",
      "Iteración: 1000, Error: 2.385527\n",
      "\n",
      "\n",
      "Iteración: 1100, Error: 2.383725\n",
      "\n",
      "\n",
      "Iteración: 1200, Error: 2.320323\n",
      "\n",
      "\n",
      "Iteración: 1300, Error: 2.351162\n",
      "\n",
      "\n",
      "Iteración: 1400, Error: 2.397342\n",
      "\n",
      "\n",
      "Iteración: 1500, Error: 2.281643\n",
      "\n",
      "\n",
      "Iteración: 1600, Error: 2.411718\n",
      "\n",
      "\n",
      "Iteración: 1700, Error: 2.352351\n",
      "\n",
      "\n",
      "Iteración: 1800, Error: 2.317065\n",
      "\n",
      "\n",
      "Iteración: 1900, Error: 2.307435\n",
      "\n",
      "\n",
      "Iteración: 2000, Error: 2.242700\n",
      "\n",
      "\n",
      "Iteración: 2100, Error: 2.242531\n",
      "\n",
      "\n",
      "Iteración: 2200, Error: 2.218364\n",
      "\n",
      "\n",
      "Iteración: 2300, Error: 2.237181\n",
      "\n",
      "\n",
      "Iteración: 2400, Error: 2.274931\n",
      "\n",
      "\n",
      "Iteración: 2500, Error: 2.297844\n",
      "\n",
      "\n",
      "Iteración: 2600, Error: 2.186688\n",
      "\n",
      "\n",
      "Iteración: 2700, Error: 2.320674\n",
      "\n",
      "\n",
      "Iteración: 2800, Error: 2.306735\n",
      "\n",
      "\n",
      "Iteración: 2900, Error: 2.263267\n",
      "\n",
      "\n",
      "Iteración: 3000, Error: 2.169670\n",
      "\n",
      "\n",
      "Iteración: 3100, Error: 2.307051\n",
      "\n",
      "\n",
      "Iteración: 3200, Error: 2.257058\n",
      "\n",
      "\n",
      "Iteración: 3300, Error: 2.316653\n",
      "\n",
      "\n",
      "Iteración: 3400, Error: 2.281657\n",
      "\n",
      "\n",
      "Iteración: 3500, Error: 2.165466\n",
      "\n",
      "\n",
      "Iteración: 3600, Error: 2.146515\n",
      "\n",
      "\n",
      "Iteración: 3700, Error: 2.260412\n",
      "\n",
      "\n",
      "Iteración: 3800, Error: 2.248911\n",
      "\n",
      "\n",
      "Iteración: 3900, Error: 2.234242\n",
      "\n",
      "\n",
      "Iteración: 4000, Error: 2.190251\n",
      "\n",
      "\n",
      "Iteración: 4100, Error: 2.204892\n",
      "\n",
      "\n",
      "Iteración: 4200, Error: 2.302195\n",
      "\n",
      "\n",
      "Iteración: 4300, Error: 2.273209\n",
      "\n",
      "\n",
      "Iteración: 4400, Error: 2.204398\n",
      "\n",
      "\n",
      "Iteración: 4500, Error: 2.233748\n",
      "\n",
      "\n",
      "Iteración: 4600, Error: 2.276993\n",
      "\n",
      "\n",
      "Iteración: 4700, Error: 2.232224\n",
      "\n",
      "\n",
      "Iteración: 4800, Error: 2.192424\n",
      "\n",
      "\n",
      "Iteración: 4900, Error: 2.138848\n",
      "\n",
      "\n",
      "Iteración: 5000, Error: 2.157093\n",
      "\n",
      "\n",
      "Iteración: 5100, Error: 2.181294\n",
      "\n",
      "\n",
      "Iteración: 5200, Error: 2.200593\n",
      "\n",
      "\n",
      "Iteración: 5300, Error: 2.172145\n",
      "\n",
      "\n",
      "Iteración: 5400, Error: 2.175688\n",
      "\n",
      "\n",
      "Iteración: 5500, Error: 2.192304\n",
      "\n",
      "\n",
      "Iteración: 5600, Error: 2.193877\n",
      "\n",
      "\n",
      "Iteración: 5700, Error: 2.197335\n",
      "\n",
      "\n",
      "Iteración: 5800, Error: 2.262244\n",
      "\n",
      "\n",
      "Iteración: 5900, Error: 2.137922\n",
      "\n",
      "\n",
      "Iteración: 6000, Error: 2.121541\n",
      "\n",
      "\n",
      "Iteración: 6100, Error: 2.229194\n",
      "\n",
      "\n",
      "Iteración: 6200, Error: 2.179889\n",
      "\n",
      "\n",
      "Iteración: 6300, Error: 2.176945\n",
      "\n",
      "\n",
      "Iteración: 6400, Error: 2.212042\n",
      "\n",
      "\n",
      "Iteración: 6500, Error: 2.205082\n",
      "\n",
      "\n",
      "Iteración: 6600, Error: 2.246514\n",
      "\n",
      "\n",
      "Iteración: 6700, Error: 2.183042\n",
      "\n",
      "\n",
      "Iteración: 6800, Error: 2.160037\n",
      "\n",
      "\n",
      "Iteración: 6900, Error: 2.196290\n",
      "\n",
      "\n",
      "Iteración: 7000, Error: 2.229490\n",
      "\n",
      "\n",
      "Iteración: 7100, Error: 2.229889\n",
      "\n",
      "\n",
      "Iteración: 7200, Error: 2.166794\n",
      "\n",
      "\n",
      "Iteración: 7300, Error: 2.246172\n",
      "\n",
      "\n",
      "Iteración: 7400, Error: 2.084583\n",
      "\n",
      "\n",
      "Iteración: 7500, Error: 2.229988\n",
      "\n",
      "\n",
      "Iteración: 7600, Error: 2.175467\n",
      "\n",
      "\n",
      "Iteración: 7700, Error: 2.146610\n",
      "\n",
      "\n",
      "Iteración: 7800, Error: 2.179994\n",
      "\n",
      "\n",
      "Iteración: 7900, Error: 2.246778\n",
      "\n",
      "\n",
      "Iteración: 8000, Error: 2.196036\n",
      "\n",
      "\n",
      "Iteración: 8100, Error: 2.246404\n",
      "\n",
      "\n",
      "Iteración: 8200, Error: 2.223307\n",
      "\n",
      "\n",
      "Iteración: 8300, Error: 2.240795\n",
      "\n",
      "\n",
      "Iteración: 8400, Error: 2.215334\n",
      "\n",
      "\n",
      "Iteración: 8500, Error: 2.192849\n",
      "\n",
      "\n",
      "Iteración: 8600, Error: 2.248153\n",
      "\n",
      "\n",
      "Iteración: 8700, Error: 2.178948\n",
      "\n",
      "\n",
      "Iteración: 8800, Error: 2.195210\n",
      "\n",
      "\n",
      "Iteración: 8900, Error: 2.245780\n",
      "\n",
      "\n",
      "Iteración: 9000, Error: 2.164906\n",
      "\n",
      "\n",
      "Iteración: 9100, Error: 2.195384\n",
      "\n",
      "\n",
      "Iteración: 9200, Error: 2.192396\n",
      "\n",
      "\n",
      "Iteración: 9300, Error: 2.248758\n",
      "\n",
      "\n",
      "Iteración: 9400, Error: 2.141850\n",
      "\n",
      "\n",
      "Iteración: 9500, Error: 2.225555\n",
      "\n",
      "\n",
      "Iteración: 9600, Error: 2.139106\n",
      "\n",
      "\n",
      "Iteración: 9700, Error: 2.200099\n",
      "\n",
      "\n",
      "Iteración: 9800, Error: 2.152840\n",
      "\n",
      "\n",
      "Iteración: 9900, Error: 2.216296\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4. ENTRENAMIENTO\n",
    "# ===========================================================\n",
    "# (2hs de ejecución)\n",
    "BATCH_SIZE = 80\t\t\t# Número de ejemplos de entrenamiento a usar en cada iteración\n",
    "NITS = 10000\t\t\t# Número de iteraciones\n",
    "\n",
    "for j in range(NITS):\n",
    "#    historia = modelo.fit_generator(train_generator(), steps_per_epoch=BATCH_SIZE, epochs=1, verbose=0)\n",
    "    historia = modelo.fit(train_generator(), steps_per_epoch=BATCH_SIZE, epochs=1, verbose=0)\n",
    "\n",
    "    # Imprimir evolución del entrenamiento cada 1000 iteraciones\n",
    "    if j%100 == 0:\n",
    "        print('\\nIteración: %d, Error: %f' % (j, historia.history['loss'][0]) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "daily-agency",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. GENERACIÓN DE NOMBRES USANDO EL MODELO ENTRENADO\n",
    "# ===========================================================\n",
    "def generar_nombre(modelo,car_a_num,tam_alfabeto,n_a):\n",
    "    # Inicializar x y a con ceros\n",
    "    x = np.zeros((1,1,tam_alfabeto,))\n",
    "    a = np.zeros((1, n_a))\n",
    "\n",
    "    # Nombre generado y caracter de fin de linea\n",
    "    nombre_generado = ''\n",
    "    fin_linea = '\\n'\n",
    "    car = -1\n",
    "\n",
    "    # Iterar sobre el modelo y generar predicción hasta tanto no se alcance\n",
    "    # \"fin_linea\" o el nombre generado llegue a los 50 caracteres\n",
    "    contador = 0\n",
    "    while (car != fin_linea and contador != 50):\n",
    "          # Generar predicción usando la celda RNN\n",
    "          a, _ = celda_recurrente(K.constant(x), initial_state=K.constant(a))\n",
    "          y = capa_salida(a)\n",
    "          prediccion = K.eval(y)\n",
    "\n",
    "          # Escoger aleatoriamente un elemento de la predicción (el elemento con\n",
    "          # con probabilidad más alta tendrá más opciones de ser seleccionado)\n",
    "          ix = np.random.choice(list(range(tam_alfabeto)),p=prediccion.ravel())\n",
    "\n",
    "          # Convertir el elemento seleccionado a caracter y añadirlo al nombre generado\n",
    "          car = ind_a_car[ix]\n",
    "          nombre_generado += car\n",
    "\n",
    "          # Crear x_(t+1) = y_t, y a_t = a_(t-1)\n",
    "          x = to_categorical(ix,tam_alfabeto).reshape(1,1,tam_alfabeto)\n",
    "          a = K.eval(a)\n",
    "\n",
    "          # Actualizar contador y continuar\n",
    "          contador += 1\n",
    "\n",
    "          # Agregar fin de línea al nombre generado en caso de tener más de 50 caracteres\n",
    "          if (contador == 50):\n",
    "            nombre_generado += '\\n'\n",
    "\n",
    "    print(nombre_generado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "sublime-salad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zseurusaucagauvoeguaexaunphocovuatkusauseruaepatol\n",
      "\n",
      "ausiapon\n",
      "\n",
      "s\n",
      "\n",
      "lhuewururustous\n",
      "\n",
      "dzuranausaudongrobotodurususn\n",
      "\n",
      "ausaususopntauteohoveodtoauatolopotos\n",
      "\n",
      "s\n",
      "\n",
      "aus\n",
      "\n",
      "uanalushxisanongonouruannoslus\n",
      "\n",
      "guroustaurusausatyurustiosan\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generar 10 ejemplos de nombres generados por el modelo ya entrenado\n",
    "for i in range(10):\n",
    "    generar_nombre(modelo,car_a_ind,tam_alfabeto,n_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "tested-geometry",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.save('rnn_gen_nombres.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
