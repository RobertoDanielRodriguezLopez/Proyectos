{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **PIPELINE**\n",
    "\n",
    "En esta última práctica, veremos cómo realizar la puesta en producción de un modelo de Machine Learning.\n",
    "\n",
    "El pipeline es una forma de codificar y automatizar el workflow necesario para producir un modelo de Machine Learning. Los pipelines en ML constan de varios pasos secuenciales que hacen de todo, desde la extracción y el preprocesamiento de datos hasta el entrenamiento y la implementación de modelos.\n",
    "\n",
    "En definitiva, nos ayuda a automatizar un flujo de trabajo de Machine Learning.\n",
    "\n",
    "<img src = \"../_src/assets/pipeline_2.jpg\" height = 350>\n",
    "\n",
    "Uno de sus grandes beneficios y aplicabilidad reside en la escalabilidad. A su vez, destaca entre sus ventajas que simplifica la aplicación de cross-validation y optimización de hiperparámetros.\n",
    "\n",
    "Con este enfoque, podemos *empaquetar* todas las acciones que van desde el preprocesamiento de los datos hasta las predicciones del modelo en un único objeto.\n",
    "\n",
    "La librería `Scikit-learn` incluye una clase, denominada precisamente **pipeline**, que está diseñada para poder manipular y aplicar una serie de transformaciones de datos seguida de la aplicación de un modelo de ML. En otras palabras, con esta clase podemos instanciar un objeto que incluya todo el flujo del preprocesamiento de datos -desde la limpieza, normalización, escalado, transformación, reducción de dimensionalidad hasta ingeniería de features- y el modelo predictivo con el cual haremos las inferencias.\n",
    "\n",
    "También Scikit-learn nos brinda la posibilidad de hacer nuestro pipeline con la clase **make_pipeline**. Veamos brevemente en qué se diferencia una de la otra.\n",
    "\n",
    "|Pipeline|Make_pipeline|\n",
    "|-|-|\n",
    "|Hay que especificar todos los pasos secuenciales en una lista|No hay que indicar un nombre para cada paso|\n",
    "|Cada paso es una tupla con el nombre del paso y su nombre oficial en Scikit-learn|Se pueden encadenar todos los pasos usando sus nombres oficiales en Scikit-learn|\n",
    "|Ejemplo: `a`|Ejemplo: `b`|\n",
    "\n",
    "```python\n",
    "\n",
    "'a' Pipeline([('imputer', SimpleImputer(strategy='median')),('scaler', StandardScaler())])\n",
    "\n",
    "```\n",
    "\n",
    "```python\n",
    "\n",
    "'b' make_pipeline(SimpleImputer(strategy='median'), StandardScaler())\n",
    "\n",
    "```\n",
    "\n",
    "- - -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Práctica`\n",
    "\n",
    "Para la realización de esta práctica construiremos tres pipelines, cada uno con un modelo diferente. \n",
    "\n",
    "Primero haremos algunos pasos del preprocesamiento de datos, luego adaptaremos nuestros modelos. Para finalizar, compararemos la performance de los modelos y buscaremos identificar el mejor de ellos. Una vez obtenido, lo guardamos en un archivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos los datos con los que vamos a estar trabajando\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos los datos en train y test\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, crearemos los tres pipelines. Los modelos que usaremos serán: regresión logística, support vector machine y árbol de decisión. Respecto al preprocesamiento, aplicaremos un escalado de datos con `Standard Scaler` y haremos reducción de dimensionalidad con `PCA`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las librerías necesarias\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el primer pipeline\n",
    "\n",
    "pipe_lr = Pipeline([('scl', StandardScaler()),\n",
    "\t\t\t('pca', PCA(n_components=2)),\n",
    "\t\t\t('clf', LogisticRegression(random_state=42))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el segundo pipeline\n",
    "\n",
    "pipe_svm = Pipeline([('scl', StandardScaler()),\n",
    "\t\t\t('pca', PCA(n_components=2)),\n",
    "\t\t\t('clf', svm.SVC(random_state=42))])\n",
    "\t\t\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el tercer pipeline\n",
    "\n",
    "pipe_dt = Pipeline([('scl', StandardScaler()),\n",
    "\t\t\t('pca', PCA(n_components=2)),\n",
    "\t\t\t('clf', tree.DecisionTreeClassifier(random_state=42))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Los guardamos en una lista\n",
    "\n",
    "pipelines = [pipe_lr, pipe_svm, pipe_dt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos un diccionario para fines organizativos\n",
    "\n",
    "pipe_dict = {0: 'Regresión Logística', 1: 'SVM', 2: 'Árbol de decisión'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamos\n",
    "\n",
    "for pipe in pipelines:\n",
    "\tpipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regresión Logística pipeline accuracy en test: 0.900\n",
      "SVM pipeline accuracy en test: 0.900\n",
      "Árbol de decisión pipeline accuracy en test: 0.867\n"
     ]
    }
   ],
   "source": [
    "# Evaluamos\n",
    "\n",
    "for idx, val in enumerate(pipelines):\n",
    "\tprint('%s pipeline accuracy en test: %.3f' % (pipe_dict[idx], val.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo con el mejor accuracy: Regresión Logística\n"
     ]
    }
   ],
   "source": [
    "# Identificamos el mejor modelo para el set de testeo\n",
    "\n",
    "best_acc = 0.0\n",
    "best_clf = 0\n",
    "best_pipe = ''\n",
    "for idx, val in enumerate(pipelines):\n",
    "\tif val.score(X_test, y_test) > best_acc:\n",
    "\t\tbest_acc = val.score(X_test, y_test)\n",
    "\t\tbest_pipe = val\n",
    "\t\tbest_clf = idx\n",
    "print('Modelo con el mejor accuracy: %s' % pipe_dict[best_clf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline de Regresión Logística guardado a archivo\n"
     ]
    }
   ],
   "source": [
    "# Guardamos el pipeline en un archivo\n",
    "\n",
    "import joblib #pickle es alternativa\n",
    "\n",
    "joblib.dump(best_pipe, 'Mejor_pipeline.pkl', compress=1)\n",
    "print('Pipeline de %s guardado a archivo' % pipe_dict[best_clf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = joblib.load('Mejor_pipeline.pkl')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scl&#x27;, StandardScaler()), (&#x27;pca&#x27;, PCA(n_components=2)),\n",
       "                (&#x27;clf&#x27;, LogisticRegression(random_state=42))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scl&#x27;, StandardScaler()), (&#x27;pca&#x27;, PCA(n_components=2)),\n",
       "                (&#x27;clf&#x27;, LogisticRegression(random_state=42))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA(n_components=2)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=42)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('scl', StandardScaler()), ('pca', PCA(n_components=2)),\n",
       "                ('clf', LogisticRegression(random_state=42))])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "9b0261dadc93494a3555537365c322d83416c4a1ed03d5df7c77bc94b07686c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
